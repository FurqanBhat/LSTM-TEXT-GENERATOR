{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMV3SgHDGpbJ5YjIloja7Ex",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FurqanBhat/LSTM-TEXT-GENERATOR/blob/main/LSTM_%26_Text_Gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "O_xPu2Z7ByzQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(LSTM, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.forget_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    self.input_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    self.cell_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    self.output_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "\n",
        "  def forward(self, input, hidden, cell):\n",
        "    combined = torch.cat((input, hidden), 1)\n",
        "\n",
        "    forget_gate_output = torch.sigmoid(self.forget_gate(combined))\n",
        "    input_gate_output = torch.sigmoid(self.input_gate(combined))\n",
        "    cell_gate_output = torch.tanh(self.cell_gate(combined))\n",
        "    output_gate_output = torch.sigmoid(self.output_gate(combined))\n",
        "\n",
        "    cell = forget_gate_output * cell + input_gate_output * cell_gate_output\n",
        "    hidden = output_gate_output * torch.tanh(cell)\n",
        "\n",
        "    return hidden, cell"
      ],
      "metadata": {
        "id": "_YXxZ2Q9CDK8"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available else 'cpu')"
      ],
      "metadata": {
        "id": "S5qZFXf0zCuy"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NEWLSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.forget_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    # self.input_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    self.cell_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    self.output_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "\n",
        "  def forward(self, input, hidden, cell):\n",
        "    combined = torch.cat((input, hidden), 1)\n",
        "\n",
        "    forget_gate_output = torch.sigmoid(self.forget_gate(combined))\n",
        "    input_gate_output = 1-forget_gate_output\n",
        "    cell_gate_output = torch.tanh(self.cell_gate(combined))\n",
        "    output_gate_output = torch.sigmoid(self.output_gate(combined))\n",
        "\n",
        "    cell = forget_gate_output * cell + input_gate_output * cell_gate_output\n",
        "    hidden = output_gate_output * torch.tanh(cell)\n",
        "\n",
        "    return hidden, cell"
      ],
      "metadata": {
        "id": "c3sdQ2YazCy0"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data loading\n",
        "with open(\"shakespeare_100.txt\", \"r\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "char2idx = {ch: i for i, ch in enumerate(chars)}\n",
        "idx2char = {i: ch for ch, i in char2idx.items()}\n",
        "encoded_text = [char2idx[c] for c in text]\n",
        "\n"
      ],
      "metadata": {
        "id": "gvd4B-nmCDNh"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seq preparation\n",
        "seq_length = 100\n",
        "inputs, targets = [], []\n",
        "for i in range(0, len(encoded_text) - seq_length):\n",
        "    inputs.append(encoded_text[i:i+seq_length])\n",
        "    targets.append(encoded_text[i+1:i+seq_length+1])\n",
        "\n",
        "input_tensor = torch.tensor(inputs, dtype=torch.long)\n",
        "target_tensor = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "dataset = TensorDataset(input_tensor, target_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
      ],
      "metadata": {
        "id": "KmiLmingCDP7"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ShakespeareGenerator(nn.Module):\n",
        "    def __init__(self, vocab_size, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, input_size)\n",
        "        self.lstm = NEWLSTM(input_size, hidden_size)  # custom  LSTM\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, h, c):\n",
        "        batch_size, seq_len = x.shape\n",
        "        outputs = []\n",
        "\n",
        "        for t in range(seq_len):\n",
        "            embedded = self.embedding(x[:, t])\n",
        "            h, c = self.lstm(embedded, h, c)\n",
        "            logits = self.fc(h)\n",
        "            outputs.append(logits)\n",
        "\n",
        "        return torch.stack(outputs, dim=1), h, c"
      ],
      "metadata": {
        "id": "qtVtyVYc_JSR"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Hyperparameters & Setup ===\n",
        "input_size = 128\n",
        "hidden_size = 256\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = ShakespeareGenerator(vocab_size, input_size, hidden_size).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
        "loss_fn = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "B4Q0_9VbjgDe"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# === Training Loop ===\n",
        "start_time = time.time()  # Record the start time\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for x_batch, y_batch in dataloader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        h = torch.zeros(x_batch.size(0), hidden_size).to(device)\n",
        "        c = torch.zeros(x_batch.size(0), hidden_size).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output, _, _ = model(x_batch, h, c)\n",
        "        loss = loss_fn(output.view(-1, vocab_size), y_batch.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader):.4f}\")\n",
        "\n",
        "end_time = time.time()  # Record the end time\n",
        "training_time = end_time - start_time  # Calculate training time\n",
        "\n",
        "print(f\"Training Time: {training_time:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_5s1yQTyP0T",
        "outputId": "d00168b4-2599-4ab9-efeb-7b82d6f928db"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.6741\n",
            "Epoch 2, Loss: 1.7427\n",
            "Epoch 3, Loss: 0.9963\n",
            "Epoch 4, Loss: 0.4004\n",
            "Epoch 5, Loss: 0.1686\n",
            "Epoch 6, Loss: 0.1142\n",
            "Epoch 7, Loss: 0.0946\n",
            "Epoch 8, Loss: 0.0842\n",
            "Epoch 9, Loss: 0.0779\n",
            "Epoch 10, Loss: 0.0743\n",
            "Training Time: 207.55 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "UXZSsiNVyPxg"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(model.state_dict(), './model.pth') #"
      ],
      "metadata": {
        "id": "T_dmwVumyP2-"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "source": [
        "def generate(model, start_text, char2idx, idx2char, length=100, device='cpu'):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    # Create input tensor and move it to the specified device\n",
        "    input = torch.tensor([[char2idx[c] for c in start_text]], device=device)\n",
        "    # Create hidden and cell state tensors and move them to the specified device\n",
        "    h = torch.zeros(1, model.lstm.hidden_size, device=device)\n",
        "    c = torch.zeros(1, model.lstm.hidden_size, device=device)\n",
        "\n",
        "    result = start_text\n",
        "\n",
        "    for _ in range(length):\n",
        "        out, h, c = model(input, h, c)\n",
        "        last_logits = out[0, -1]\n",
        "        probs = torch.softmax(last_logits, dim=0)\n",
        "        next_char_idx = torch.multinomial(probs, 1).item()\n",
        "        result += idx2char[next_char_idx]\n",
        "        input = torch.tensor([[next_char_idx]], device=device)\n",
        "\n",
        "    return result"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Zw_ILNwhaxp2"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "source": [
        "print(generate(model, \"End\", char2idx, idx2char, length=500, device=device))"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKLkkEkGaynZ",
        "outputId": "283b89a8-95d2-4c30-a2a1-8097b44ea0bc"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "End unkind of post.\n",
            "\n",
            "AJAX:\n",
            "O Mattle! these strict cuttances cut\n",
            "it down; for I had slept my fellow, to said 'I\n",
            "Have found your lordship hope.\n",
            "\n",
            "MARK ANTONY:\n",
            "How! I have my hanking\n",
            "that he contends, he hath restraints would not then be got as he prayers\n",
            "Which are much thus from them with thee; I am not ever thought\n",
            "To make that with a wise exclaim, as I am sure;\n",
            "To say well like a dotage on the fixed cease,\n",
            "And let mine eyes may straight sole sword conveyard,\n",
            "That dust\n",
            "it down; for I had slept my fel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YYOfoR33yfQ1"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3OX7RmEpyfTq"
      },
      "execution_count": 95,
      "outputs": []
    }
  ]
}